# Assignment Feedback: Week 4: Dimensionality Reduction

**Student:** srikanthmannepalli0502-cmyk
**Total Score:** 17/40 (42.5%)

**Grade Category:** F (Failing)

---

## Problem Breakdown

### Exercise 1 (6/16 = 37.5%)

**Part pipeline-part1** (pipeline-part1.code): 0/0 points

_Feedback:_ Good work: you fit PCA to 2 components and plotted the 2D projection colored by labels, which meets the goal. Optional improvements: report explained_variance_ratio_ and/or show inverse_transform reconstructions to visualize approximations of digits.

**Part pipeline-part2** (pipeline-part2.code): 1/4 points

_Feedback:_ You fit PCA and made a scree plot, but the task was to reduce to 2 components and show a 2D scatter colored by class. Missing n_components=2, transform, and scatter of the first two PCs with c=y_mnist_train and axis/title labels. Reuse your pca_2d setup.

**Part pipeline-part3** (pipeline-part3.code): 1/4 points

_Feedback:_ Your code computes components to reach 95% variance but does not produce the required scree plot. Missing: per-component variance for first 40 PCs, plot, and percent on y-axis. Use your prior PCA with 40 comps (e.g., pca_full.explained_variance_ratio_[:40]*100) and plot it.

**Part pipeline-part4** (pipeline-part4.code): 4/4 points

_Feedback:_ Good job. You correctly used the prefit pca_95 (n_components=0.95) and surfaced the number of components via pca_95.n_components_ in the plot title. This satisfies calculating/reporting the count for 95% variance, and the reconstruction is a nice validation.

**Part pipeline-part5** (pipeline-part5.code): 0/4 points

_Feedback:_ Your submission trains KNN and applies PCA(0.80) but does not address the task: visualize a digit using the Step 4 dimensionality (pca_95.n_components_). No transform/inverse_transform or plotting of the digit is done. Use pca_95, reconstruct a digit, and plot with plot_mnist_dig

---

### Exercise 2 (8/10 = 80.0%)

**Part ex1-part1** (ex1-part1.code): 4/4 points

_Feedback:_ Excellent. You reduced dimensionality with PCA then applied t-SNE, colored by labels, and produced a clear 2D visualization. Sensible hyperparameters (init='pca', learning_rate='auto', perplexity=30). Meets the exercise goal fully.

**Part ex1-part2** (ex1-part2.code): 2/3 points

_Feedback:_ Good use of KNN on t-SNE features and you reported accuracy. However, you fit PCA/t-SNE on the combined train+test set, causing data leakage and inflating performance. Split first and avoid fitting on test (or evaluate via CV on train). Otherwise solid attempt.

**Part ex1-part3** (ex1-part3.code): 2/3 points

_Feedback:_ You correctly trained KNN and computed accuracy with a proper train/test split. However, this exercise asked to compute KNN accuracy based on prior work (t-SNE/PCA). You switched to UMAP features instead. Good technique, but not aligned with the specified prior work.

---

### Exercise 4 (3/14 = 21.4%)

**Part ex2-part1** (ex2-part1.code): 0/0 points

_Feedback:_ You correctly applied PCA (2D/3D), visualized 2D, and evaluated KNN—good start. However, you didn’t include UMAP or vary its parameters, and dimension sweep was minimal. Add UMAP (e.g., n_neighbors, min_dist) and compare KNN accuracies and plots across dims.

**Part ex2-part2** (ex2-part2.code): 3/7 points

_Feedback:_ You implemented UMAP + KNN, not PCA as requested. This does not use your prior PCA work, so the main objective isn’t met. The pipeline and evaluation are otherwise sound. To earn credit, fit/transform with PCA and report/plot PCA-based results.

**Part ex2-part3** (ex2-part3.answer): 0/7 points

_Feedback:_ Submission contains only placeholder text - no actual student work provided.

---

## Additional Information

This feedback was automatically generated by the autograder using LLM-based evaluation.

**Generated:** 2025-10-27 18:51:26 UTC

If you have questions about your grade, please reach out to the instructor.

---

*Powered by [Grade-Lite](https://github.com/your-repo/grade-lite) Autograder*